{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uditagupta93/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['test', 'sample', 'text', 'product']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488665"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = open('big.txt').read() #read all the words from big.txt\n",
    "len(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we use re package to filter out unnecessary characters, tokenize the words and convert it to lower case\n",
    "def tokens(text):\n",
    "    return re.findall('[a-z]+', text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test', 'this', 'is']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens('This is: A test, 1, 2, 3, this is.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105285"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS = tokens(TEXT)\n",
    "len(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'adventures', 'of', 'sherlock', 'holmes']\n"
     ]
    }
   ],
   "source": [
    "print(WORDS[:10]) #print first few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(bag, n=10):\n",
    "    return ' '.join(random.choice(bag) for _ in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'will whole for country and young court must the issued'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 2, 'is': 2, 'it': 1, 'test': 2, 'this': 1})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tokens('Is this a test? It is a test!')) #to make up something like a dictionary to store the number of occourences of every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 80030), ('of', 40025), ('and', 38313), ('to', 28766), ('in', 22050), ('a', 21155), ('that', 12512), ('he', 12401), ('was', 11410), ('it', 10681)]\n"
     ]
    }
   ],
   "source": [
    "COUNTS = Counter(WORDS)\n",
    "\n",
    "print(COUNTS.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 80030\n",
      "rare 83\n",
      "and 38313\n",
      "neverbeforeseen 0\n",
      "words 460\n"
     ]
    }
   ],
   "source": [
    "for w in tokens('the rare and neverbeforeseen words'):\n",
    "    print(w,COUNTS[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Checker\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    #Generating all the words with edit distance of 0, 1 & 2\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    #print(candidates)\n",
    "    #print(COUNTS.get)\n",
    "    return max(candidates, key=COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    #Return the subset of words that are actually in the dictionary.\"\n",
    "    return {w for w in words if w in COUNTS}\n",
    "\n",
    "def edits0(word): \n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for `edits1(word)`: the set of candidate words that are one edit away. For example, given `\"wird\"`, this would include `\"weird\"` (inserting an `e`) and `\"word\"` (replacing a `i` with a `o`), and also `\"iwrd\"` (transposing `w` and `i`; then `known` can be used to filter this out of the set of final candidates). How could we get them?  One way is to *split* the original word in all possible places, each split forming a *pair* of words, `(a, b)`, before and after the place, and at each place, either delete, transpose, replace, or insert a letter:\n",
    "\n",
    "<table>\n",
    "  <tr><td> pairs: <td><tt> Ø+wird <td><tt> w+ird <td><tt> wi+rd <td><tt>wir+d<td><tt>wird+Ø<td><i>Notes:</i><tt> (<i>a</i>, <i>b</i>)</tt> pair</i>\n",
    "  <tr><td> deletions: <td><tt>Ø+ird<td><tt> w+rd<td><tt> wi+d<td><tt> wir+Ø<td><td><i>Delete first char of b</i>\n",
    "  <tr><td> transpositions: <td><tt>Ø+iwrd<td><tt> w+rid<td><tt> wi+dr</tt><td><td><td><i>Swap first two chars of b\n",
    "  <tr><td> replacements: <td><tt>Ø+?ird<td><tt> w+?rd<td><tt> wi+?d<td><tt> wir+?</tt><td><td><i>Replace char at start of b\n",
    "  <tr><td> insertions: <td><tt>Ø+?+wird<td><tt> w+?+ird<td><tt> wi+?+rd<td><tt> wir+?+d<td><tt> wird+?+Ø</tt><td><i>Insert char between a and b\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def splits(word):\n",
    "    return [(word[:i], word[i:]) \n",
    "            for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'wird'), ('w', 'ird'), ('wi', 'rd'), ('wir', 'd'), ('wird', '')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('wird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wird'}\n"
     ]
    }
   ],
   "source": [
    "print(edits0('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wsrd', 'wpird', 'widd', 'wurd', 'wirdw', 'wnird', 'wtrd', 'wiro', 'wiurd', 'awird', 'wikd', 'wixd', 'wkird', 'wirxd', 'wsird', 'rird', 'bwird', 'wqird', 'wirw', 'wiud', 'gwird', 'woird', 'wrird', 'wirdn', 'wicrd', 'wrrd', 'dwird', 'wimrd', 'wiod', 'wxrd', 'wbird', 'wfrd', 'wigrd', 'wird', 'wirqd', 'wirgd', 'wirdz', 'wirf', 'bird', 'mwird', 'wirdq', 'iwird', 'hird', 'pwird', 'wiprd', 'waird', 'wyird', 'wifrd', 'wirdl', 'wlrd', 'wiid', 'pird', 'ewird', 'nird', 'wiri', 'wirm', 'wxird', 'wizrd', 'wjird', 'wrd', 'uird', 'wprd', 'wirdr', 'yird', 'whird', 'wkrd', 'wifd', 'wirq', 'wrid', 'wirr', 'wbrd', 'wirdc', 'nwird', 'jird', 'wgrd', 'wirn', 'wirdy', 'wijrd', 'wirv', 'kird', 'wirmd', 'wirad', 'dird', 'eird', 'wire', 'wirdb', 'wirud', 'twird', 'wirhd', 'wirdh', 'iird', 'vird', 'wcrd', 'wierd', 'wisd', 'kwird', 'swird', 'wcird', 'wiyrd', 'wirld', 'wirdk', 'wuird', 'lwird', 'wisrd', 'werd', 'wirkd', 'owird', 'wivd', 'wyrd', 'weird', 'wicd', 'wied', 'wirh', 'wirk', 'wirdi', 'wfird', 'xwird', 'wirdx', 'zird', 'wijd', 'wirdt', 'wzrd', 'wirdm', 'wirtd', 'wirds', 'wirj', 'wirzd', 'wjrd', 'fird', 'wirz', 'wvrd', 'ird', 'wmrd', 'wibrd', 'wiwrd', 'wiwd', 'wixrd', 'widrd', 'wirrd', 'wirdd', 'wirod', 'wiyd', 'wired', 'wizd', 'zwird', 'wiord', 'qwird', 'wild', 'wiqd', 'wircd', 'wiird', 'wirdu', 'oird', 'wwrd', 'wirwd', 'wirg', 'wirdj', 'xird', 'wiad', 'wihrd', 'ward', 'widr', 'wirt', 'wvird', 'wgird', 'wirdv', 'fwird', 'wipd', 'wirde', 'wikrd', 'jwird', 'wirp', 'wdird', 'wirid', 'wtird', 'aird', 'wirnd', 'wiru', 'whrd', 'sird', 'wibd', 'witrd', 'wirl', 'wirdg', 'wirvd', 'wimd', 'wirpd', 'word', 'wind', 'wirsd', 'wiryd', 'iwrd', 'wirdp', 'wirc', 'wirfd', 'lird', 'wirjd', 'rwird', 'tird', 'wirdo', 'vwird', 'wirdf', 'mird', 'wnrd', 'witd', 'wirda', 'wirx', 'wzird', 'wiqrd', 'wirbd', 'wihd', 'wirb', 'wlird', 'wir', 'wid', 'wirs', 'cwird', 'uwird', 'winrd', 'wivrd', 'qird', 'ywird', 'hwird', 'wigd', 'wwird', 'wmird', 'wiard', 'wdrd', 'gird', 'wilrd', 'cird', 'wira', 'wqrd', 'wiry'}\n"
     ]
    }
   ],
   "source": [
    "print(edits1('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24254\n"
     ]
    }
   ],
   "source": [
    "print(len(edits2('wird')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spelling',\n",
       " 'errors',\n",
       " 'in',\n",
       " 'something',\n",
       " 'whatever',\n",
       " 'unusual',\n",
       " 'mistakes',\n",
       " 'everywhere']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(correct, tokens('Speling errurs in somethink. Whutever; unusuel misteakes everyware?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WRONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>contenpted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>begining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>problam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dirven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>exstacy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       WRONG\n",
       "0   0  contenpted\n",
       "1   1    begining\n",
       "2   2     problam\n",
       "3   3      dirven\n",
       "4   4     exstacy"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.drop('ID', axis=1)\n",
    "test_list = test_df['WRONG'].tolist()\n",
    "#print(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we make the output prettier than that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "\n",
    "def correct_match(match):\n",
    "    word = match.group()\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "def case_of(text):\n",
    "    return (str.upper if text.isupper() else\n",
    "            str.lower if text.islower() else\n",
    "            str.title if text.istitle() else\n",
    "            str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_list =[]\n",
    "for text in test_list:\n",
    "    correct_list.append(correct_text(text))\n",
    "    \n",
    "#print(correct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = \"sample_test_submit.csv\"\n",
    "\n",
    "#Assuming res is a flat list\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in correct_list:\n",
    "        writer.writerow([val])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://web.stanford.edu/class/cs276/pa/pa2.p\n",
    "\n",
    "http://web.stanford.edu/~jurafsky/slp3/5.pdf\n",
    "\n",
    "http://norvig.com/ngrams/spell-errors.txt\n",
    "\n",
    "http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb\n",
    "\n",
    "http://norvig.com/big.txt\n",
    "\n",
    "http://norvig.com/ngrams/count_1w.txt\n",
    "\n",
    "http://norvig.com/ngrams/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
